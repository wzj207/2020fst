{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "water_check.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHrBMICKIUiEmsnlqX+cku",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wzj207/2020fst/blob/master/water_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtyYWc1lAUmS"
      },
      "source": [
        "import torch\n",
        "torch.__version__, torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVWnX0UiI2o"
      },
      "source": [
        "import requests\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJYw_0cmiJHW"
      },
      "source": [
        "species = 'Passer domesticus'\n",
        "species_folder = os.path.join('images', species)\n",
        "\n",
        "file_path_1 = 'House x Italian Sparrow (hybrid) - Passer domesticus x italiae.txt'\n",
        "def get_ids_from_txt(file_path):\n",
        "    with open(file_path) as f:\n",
        "        ids = f.read()\n",
        "        ids = ids.split(',')\n",
        "        print(len(ids))\n",
        "        return ids\n",
        "ids_1 = get_ids_from_txt(file_path_1)\n",
        "\n",
        "\n",
        "assertIdsListRockPigeon_Columbalivia = ids_1\n",
        "assertIdsSetRockPigeon_Columbalivia = set(assertIdsListRockPigeon_Columbalivia)\n",
        "\n",
        "os.makedirs(species_folder, exist_ok=True)\n",
        "\n",
        "current_list = assertIdsListRockPigeon_Columbalivia\n",
        "current_set = assertIdsSetRockPigeon_Columbalivia\n",
        "print(len(current_list))\n",
        "print(len(current_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0DzrVw6iJJ-"
      },
      "source": [
        "def get_images(current_set):\n",
        "    for i, id in enumerate(current_set):\n",
        "        url_of_single_image = f'https://cdn.download.ams.birds.cornell.edu/api/v1/asset/{id}/1200'\n",
        "        response = requests.get(url_of_single_image)\n",
        "        time.sleep(0.05)\n",
        "        print('wait for 2 ms...')\n",
        "        if response.ok:  # .status_code == 200:\n",
        "            print(f'Code: {response.status_code}, url: {url_of_single_image}')\n",
        "            save_fn = os.path.join(species_folder, str(id)+'.jpg')\n",
        "            if not os.path.exists(save_fn):\n",
        "                with open(save_fn, 'wb') as f:\n",
        "                    f.write(response.content)\n",
        "        print(f'{len(os.listdir(species_folder))} images has/have been saved.')\n",
        "\n",
        "get_images(current_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdflmlqkiJMt"
      },
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "path = '/content/drive/'\n",
        "drive.mount(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw_K_9iry4me"
      },
      "source": [
        "os.listdir(path+'/MyDrive/Colab Notebooks/datadir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PA3TCMCwwk5"
      },
      "source": [
        "shutil.copytree(path+'/MyDrive/Colab Notebooks/datadir', 'datadir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TclrtOd0Gfc"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "data_dir = './datadir'\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(5),\n",
        "        transforms.ColorJitter(),\n",
        "        # transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        # ReshapeTransform((-1,)) # flattens the data\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        # transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        # ReshapeTransform((-1,)) # flattens the data\n",
        "    ]),\n",
        "\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        # transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        # ReshapeTransform((-1,)) # flattens the data\n",
        "    ]),\n",
        "}\n",
        "\n",
        "## load the correspoding folders\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val','test']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLkTgEtL1qmF"
      },
      "source": [
        "len(image_datasets['train']),len(image_datasets['val']),len(image_datasets['test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPPRivvaiJPV"
      },
      "source": [
        "# os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, targets = batch\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "        targets = torch.reshape(targets.type(torch.cuda.FloatTensor), (len(targets), 1))\n",
        "        #targets = torch.reshape(targets.type(torch.float), (len(targets), 1))\n",
        "        out = self(images)\n",
        "        loss = F.binary_cross_entropy(out, targets)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, targets = batch\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "        targets = torch.reshape(targets.type(torch.cuda.FloatTensor), (len(targets), 1))\n",
        "        #targets = torch.reshape(targets.type(torch.float), (len(targets), 1))\n",
        "        out = self(images)  # Generate predictions\n",
        "        loss = F.binary_cross_entropy(out, targets)  # Calculate loss\n",
        "        score = F_score(out, targets)\n",
        "        return {'val_loss': loss.detach(), 'val_score': score.detach()}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()  # Combine losses\n",
        "        batch_scores = [x['val_score'] for x in outputs]\n",
        "        epoch_score = torch.stack(batch_scores).mean()  # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_score']))\n",
        "\n",
        "\n",
        "class HabitatElementRegResnet50(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet50(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, 1)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "    def freeze(self):\n",
        "        # To freeze the residual layers\n",
        "        for param in self.network.parameters():\n",
        "            param.require_grad = False\n",
        "        for param in self.network.fc.parameters():\n",
        "            param.require_grad = True\n",
        "\n",
        "    def unfreeze(self):\n",
        "        # Unfreeze all layers\n",
        "        for param in self.network.parameters():\n",
        "            param.require_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJc61V76iJR9"
      },
      "source": [
        "print(device)\n",
        "model = HabitatElementRegResnet50().to(device)\n",
        "sample = torch.randn(1, 3, 224, 224).to(device)\n",
        "print(model(sample))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXrqBK2Et3WY"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57VMBGiS2SRE"
      },
      "source": [
        "## load the entire dataset; we are not using minibatches here\n",
        "train_loader = torch.utils.data.DataLoader(image_datasets['train'], batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(image_datasets['val'], batch_size=32, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(image_datasets['test'], batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3CTaJ6z21IC"
      },
      "source": [
        "def F_score(output, label, threshold=0.5, beta=1):\n",
        "    prob = output > threshold\n",
        "    label = label > threshold\n",
        "\n",
        "    TP = (prob & label).sum(1).float()\n",
        "    TN = ((~prob) & (~label)).sum(1).float()\n",
        "    FP = (prob & (~label)).sum(1).float()\n",
        "    FN = ((~prob) & label).sum(1).float()\n",
        "\n",
        "    precision = torch.mean(TP / (TP + FP + 1e-12))\n",
        "    recall = torch.mean(TP / (TP + FN + 1e-12))\n",
        "    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n",
        "    return F2.mean(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxxaBHAft3ZH"
      },
      "source": [
        "model.freeze()\n",
        "\n",
        "epochs = 100\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam\n",
        "\n",
        "# start_time = time.time()\n",
        "\n",
        "history = []\n",
        "history += fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n",
        "                          grad_clip=grad_clip,\n",
        "                          weight_decay=weight_decay,\n",
        "                          opt_func=opt_func)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQvv6idLb-0O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVD380nCLPJf"
      },
      "source": [
        "torch.save(model, 'resnet50_100epochs_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAd4o-LS7CIx"
      },
      "source": [
        "torch.save(model.state_dict(),'resnet50_100epochs_model_state.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sHTGkROt3b4"
      },
      "source": [
        "def plot_scores(history):\n",
        "    scores = [x['val_score'] for x in history]\n",
        "    plt.plot(scores, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('score')\n",
        "    plt.title('F1 score vs. No. of epochs')\n",
        "    plt.savefig(\"CNN_scores_no_augmentation\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs')\n",
        "    plt.savefig(\"CNN_losses_no_augmentation\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_lrs(history):\n",
        "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
        "    plt.plot(lrs)\n",
        "    plt.xlabel('Batch no.')\n",
        "    plt.ylabel('Learning rate')\n",
        "    plt.title('Learning Rate vs. Batch no.')\n",
        "    plt.savefig(\"CNN_lrs_no_augmentation\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eobUWgGNt3ep"
      },
      "source": [
        "plot_lrs(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUGjn2A5t3hQ"
      },
      "source": [
        "plot_losses(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIdJvjrft3j4"
      },
      "source": [
        "plot_scores(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s_PJ5SCt3mp"
      },
      "source": [
        "model_load = torch.load('resnet50_100epochs_model.pt')\n",
        "sample = torch.randn(1, 3, 224, 224).to(device)\n",
        "model_load(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il3MQPmAMNm3"
      },
      "source": [
        "@torch.no_grad()\n",
        "def predict_dl(dl, model, threshold=0.5):\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_probs = []\n",
        "    batch_y = []\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    for xb, yb in tqdm(dl):\n",
        "      xb = xb.to(device)\n",
        "      probs = model(xb)\n",
        "      batch_probs.append(probs.cpu().detach())\n",
        "      batch_y.append(yb)\n",
        "    batch_probs = torch.cat(batch_probs)\n",
        "    return [int(x) for x in batch_probs>threshold], [int(y.item()) for y in batch_y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFz99GiMNYpm"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_gJyJDnMNpd"
      },
      "source": [
        "dl = test_loader\n",
        "model = model_load\n",
        "p1, y1 = predict_dl(dl, model, threshold=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHEOrxxyMNsL"
      },
      "source": [
        "dl = test_loader\n",
        "model = model\n",
        "p2, y2 = predict_dl(dl, model, threshold=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUHSq6ogPFl0"
      },
      "source": [
        "for y, yy in zip(y1, y2):\n",
        "  if y != yy:\n",
        "    print(y, yy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9LO7tHwPFr0"
      },
      "source": [
        "actual_label = test_loader.dataset.targets\n",
        "# actual_label\n",
        "for yb, l in zip(y1, actual_label):\n",
        "  if yb != l:\n",
        "    print(yb, l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siC_vB79MNuf"
      },
      "source": [
        "test_preds = p1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsUreWodMNxc"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "f1 = f1_score(actual_label, test_preds)\n",
        "f_score = float(np.array(F_score(torch.tensor(np.array(test_preds).reshape(len(test_preds), 1)), torch.tensor(np.array(actual_label).reshape(len(actual_label), 1)))))\n",
        "accuracy = accuracy_score(actual_label, test_preds)\n",
        "cm = confusion_matrix(actual_label, test_preds)\n",
        "report = classification_report(actual_label, test_preds)\n",
        "\n",
        "print(\"Model F-Score (Test Data): \", f_score)\n",
        "print(\"Model F1-Score (Test Data): \", f1)\n",
        "print(\"Model Accuracy: \", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAKiUJqPSJbz"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in \"01\"], columns = [i for i in \"01\"])\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(df_cm, cmap=\"Oranges\", annot=True, annot_kws={\"size\": 16})\n",
        "plt.title(\"Plot of Confusion Matrix\")\n",
        "\n",
        "plt.savefig(\"ResNet50_CM\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hQhcI3ISYQD"
      },
      "source": [
        "model2 = HabitatElementRegResnet50()\n",
        "ckpt = 'resnet50_100epochs_model_state.pt'\n",
        "is_cuda = (device != 'cpu')\n",
        "checkpoint = torch.load(ckpt, map_location=None if is_cuda else torch.device('cpu'))\n",
        "model2.load_state_dict(checkpoint)\n",
        "print('Loaded model from [{}].'.format(ckpt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc-CrrmObMjv"
      },
      "source": [
        "# torch.save(opt_func())\n",
        "opt_func"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDa53ew1TR0U"
      },
      "source": [
        "dl = test_loader\n",
        "model = model2\n",
        "p3, y3 = predict_dl(dl, model, threshold=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HGfNgZwTbUa"
      },
      "source": [
        "test_preds = p3\n",
        "f1 = f1_score(actual_label, test_preds)\n",
        "f_score = float(np.array(F_score(torch.tensor(np.array(test_preds).reshape(len(test_preds), 1)), torch.tensor(np.array(actual_label).reshape(len(actual_label), 1)))))\n",
        "accuracy = accuracy_score(actual_label, test_preds)\n",
        "cm = confusion_matrix(actual_label, test_preds)\n",
        "report = classification_report(actual_label, test_preds)\n",
        "\n",
        "print(\"Model F-Score (Test Data): \", f_score)\n",
        "print(\"Model F1-Score (Test Data): \", f1)\n",
        "print(\"Model Accuracy: \", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLT-IIEcTtq8"
      },
      "source": [
        "df_cm = pd.DataFrame(cm, index = [i for i in \"01\"], columns = [i for i in \"01\"])\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(df_cm, cmap=\"Oranges\", annot=True, annot_kws={\"size\": 16})\n",
        "plt.title(\"Plot of Confusion Matrix\")\n",
        "\n",
        "plt.savefig(\"ResNet50_CM\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBguThVjT41S"
      },
      "source": [
        "from PIL import Image\n",
        "waters = os.listdir('./datadir/test/with_water')\n",
        "zeros = 0\n",
        "ones = 0\n",
        "for water in waters:\n",
        "  # print(water)\n",
        "  sample_img = Image.open('/content/datadir/test/with_water/'+water)\n",
        "  # sample_img = Image.open('/content/datadir/test/without_water/305726081.jpg')\n",
        "\n",
        "  sample_tensor = data_transforms['test'](sample_img).unsqueeze(0).to(device)\n",
        "  p = int(model2(sample_tensor) > 0.5)\n",
        "  if p == 0:\n",
        "    zeros += 1\n",
        "  else:\n",
        "    ones += 1\n",
        "print('zeros:',zeros, 'ones:', ones)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6uAXRwkYZWh"
      },
      "source": [
        "nowaters = os.listdir('./datadir/test/without_water')\n",
        "zeros = 0\n",
        "ones = 0\n",
        "for nowater in nowaters:\n",
        "  # print(water)\n",
        "  img = Image.open('/content/datadir/test/without_water/'+nowater).convert('RGB')\n",
        "  sample_tensor = data_transforms['test'](img).unsqueeze(0).to(device)\n",
        "  p = int(model2(sample_tensor) > 0.5)\n",
        "  if p == 0:\n",
        "    zeros += 1\n",
        "  else:\n",
        "    ones += 1\n",
        "print('zeros:',zeros, 'ones:', ones)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmClz6ucZ_Yn"
      },
      "source": [
        "# 0:with_water\n",
        "# 1:wiout_water"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urZubmLlcK6W"
      },
      "source": [
        "model3 = HabitatElementRegResnet50()\n",
        "is_cuda = (device != 'cpu')\n",
        "checkpoint = model2.state_dict()\n",
        "model3.load_state_dict(checkpoint)\n",
        "\n",
        "dl = test_loader\n",
        "model = model2\n",
        "p4, y4 = predict_dl(dl, model3, threshold=0.5)\n",
        "\n",
        "test_preds = p4\n",
        "f1 = f1_score(actual_label, test_preds)\n",
        "f_score = float(np.array(F_score(torch.tensor(np.array(test_preds).reshape(len(test_preds), 1)), torch.tensor(np.array(actual_label).reshape(len(actual_label), 1)))))\n",
        "accuracy = accuracy_score(actual_label, test_preds)\n",
        "cm = confusion_matrix(actual_label, test_preds)\n",
        "report = classification_report(actual_label, test_preds)\n",
        "\n",
        "print(\"Model F-Score (Test Data): \", f_score)\n",
        "print(\"Model F1-Score (Test Data): \", f1)\n",
        "print(\"Model Accuracy: \", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjhufIY0AYBB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqhE6gRldnow"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}